{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoding: utf-8\n",
    "import json\n",
    "from pprint import pprint\n",
    "def address(file_name):\n",
    "    with open(file_name) as fp:\n",
    "        data = json.load(fp)\n",
    "    order_attributes = data['order_attributes']\n",
    "    address_name = []\n",
    "    for attr in order_attributes:\n",
    "        if attr['attr_id'] == 158:\n",
    "            address_name.append(attr['attr_value'])\n",
    "    return address_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "北京市望京soho\n",
      "16.5716671944\n",
      "0.00110101699829\n",
      "0.00137186050415\n"
     ]
    }
   ],
   "source": [
    "# time of process\n",
    "from ltpout_try import model_load, parse_sentence, address_extract\n",
    "from time import time\n",
    "start = time()\n",
    "import chardet\n",
    "segmentor, postagger, parser = model_load()\n",
    "end = time()\n",
    "words, postags, arcs  = parse_sentence(segmentor, postagger, parser)\n",
    "end1 = time()\n",
    "solution = address_extract(words, postags, arcs)\n",
    "end2 = time()\n",
    "for temp in solution:\n",
    "    print(temp)\n",
    "print(end-start)  # time to load modules\n",
    "print(end1-end)\n",
    "print(end2-end)   # time to process sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "东四北大街107号科林大厦，B座107室\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regular = re.compile(r\"[' '\\-()/]\")\n",
    "print ''.join(regular.split('东四北大街107号/科林大厦，B座107室'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799479687813\n"
     ]
    }
   ],
   "source": [
    "# accuracy to recognize the whole address when given an address\n",
    "right_count = 0.0\n",
    "total_count = 0.0\n",
    "\n",
    "for i in range(1,5000):\n",
    "    file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(i)\n",
    "    #print file_name\n",
    "    #print file_name\n",
    "    address_name = address(file_name)\n",
    "    for name in address_name:\n",
    "        #print name\n",
    "        total_count += 1\n",
    "        name = ''.join(regular.split(name))\n",
    "        \n",
    "        words, postags, arcs  = parse_sentence(segmentor, postagger, parser, name.encode('utf-8'))\n",
    "        solution = address_extract(words, postags, arcs)\n",
    "        \n",
    "        if len(solution) == 0:\n",
    "            #print name\n",
    "            #print '\\n'\n",
    "            pass\n",
    "        elif solution[0].decode('utf-8') != name:\n",
    "            #print name\n",
    "            for temp in solution:\n",
    "                #print temp\n",
    "                pass\n",
    "            #print '\\n'\n",
    "        else:\n",
    "            right_count +=1\n",
    "print(right_count/total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def message(file_name):\n",
    "    with open(file_name) as fp:\n",
    "        data = json.load(fp)\n",
    "    #print file_name\n",
    "    order_attributes = data['conversation']\n",
    "    #print order_attributes\n",
    "    conversation = []\n",
    "    for conver in order_attributes:\n",
    "        #＃print conver\n",
    "        soup = BeautifulSoup(conver['msg'], 'lxml')\n",
    "        name = soup.get_text()\n",
    "        #print name\n",
    "        conversation.append(name)\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(1102)\n",
    "conversation = message(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上海市泰康路274弄13号气味博物馆\n",
      "上海市黄浦区泰康路\n",
      "弄13号气味博物馆\n",
      "上海市黄浦区泰康路\n",
      "弄13号气味博物馆\n"
     ]
    }
   ],
   "source": [
    "for name in conversation:\n",
    "    #print name\n",
    "    words, postags, arcs  = parse_sentence(segmentor, postagger, parser, name.encode('utf-8'))\n",
    "    solution = address_extract(words, postags, arcs)\n",
    "    for temp in solution:\n",
    "        print(temp)\n",
    "        #pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,3000):\n",
    "    file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(i)\n",
    "    conversation = message(file_name)\n",
    "    #print i\n",
    "    for name in conversation:\n",
    "        words, postags, arcs  = parse_sentence(segmentor, postagger, parser, name.encode('utf-8'))\n",
    "        solution = address_extract(words, postags, arcs)\n",
    "        for temp in solution:\n",
    "            #print(temp)\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://m.laiye.com/card/index.html#!/s/23/sp/219/brand/1w01d8gKR0vOIYBz37rOeqisBgIWUsVJ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://www.namoc.org/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://r.ele.me/hq-bhkpizza\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://r.ele.me/hp-sbzp1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://r.ele.me/jmxzw\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://waimai.baidu.com/waimai/shop/1447683483\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931681585305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongtao/anaconda/lib/python2.7/site-packages/bs4/__init__.py:207: UserWarning: \"http://m.lyancoffee.com/wechat/address/base/selected/134691\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "# accuracy to extract the address when given one sentence\n",
    "right_count = 0.0\n",
    "total_count = 0.0\n",
    "import re\n",
    "for i in range(1,5000):\n",
    "    file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(i)\n",
    "    conversation = message(file_name)\n",
    "    address_name = address(file_name)\n",
    "    #print i\n",
    "    for name in conversation:\n",
    "        total_count += 1\n",
    "        for address_temp in address_name:\n",
    "            address_temp = ''.join(regular.split(address_temp))\n",
    "            name = ''.join(regular.split(name))\n",
    "            regu = re.compile(address_temp)\n",
    "            if regu.search(name):\n",
    "                out = address_temp\n",
    "            else:\n",
    "                out = ''\n",
    "        words, postags, arcs  = parse_sentence(segmentor, postagger, parser, name.encode('utf-8'))\n",
    "        solution = address_extract(words, postags, arcs)\n",
    "        if not solution and not out:\n",
    "            right_count += 1\n",
    "        elif solution and out and solution[0].decode('utf-8') == out:\n",
    "            right_count += 1\n",
    "        else:\n",
    "            #print int(total_count)\n",
    "            if solution:\n",
    "                #print '1:'+solution[0]\n",
    "                pass\n",
    "            if out:\n",
    "                #print '2:'+out\n",
    "                pass\n",
    "print right_count/total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662823580596\n"
     ]
    }
   ],
   "source": [
    "# accuracy to extract the address when given a sentence with an address\n",
    "right_count = 0.0\n",
    "total_count = 0.0\n",
    "import re\n",
    "for i in range(1,5000):\n",
    "    file_name = '/home/zhongtao/zhongtao/survey_named_entity_recognition/source/data/order_conversation/'+str(i)\n",
    "    conversation = message(file_name)\n",
    "    address_name = address(file_name)\n",
    "    #print i\n",
    "    for name in conversation:\n",
    "        for address_temp in address_name:\n",
    "            address_temp = ''.join(regular.split(address_temp))\n",
    "            name = ''.join(regular.split(name))\n",
    "            regu = re.compile(address_temp)\n",
    "            if regu.search(name):\n",
    "                total_count += 1\n",
    "                out = address_temp\n",
    "                #out = ''.join(regular.split(out))\n",
    "                words, postags, arcs  = parse_sentence(segmentor, postagger, parser, name.encode('utf-8'))\n",
    "                solution = address_extract(words, postags, arcs)\n",
    "                if solution and out and solution[0].decode('utf-8') == out:\n",
    "                    right_count += 1\n",
    "                else:\n",
    "                    if solution:\n",
    "                        #print '1:'+solution[0]\n",
    "                        pass\n",
    "                    #print '2:'+out\n",
    "print right_count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
